{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "import time\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "import cnn_drone_net_utils\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import cv2\n",
    "import io\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import datasets, transforms, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from matplotlib.pyplot import figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To start tensorboard in CMD run: 'tensorboard --logdir=runs'\n",
    "# More cool stuff with tensor board here: https://www.youtube.com/watch?v=VJW9wU-1n18 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TENSORBOARD_PATH = \"runs\"\n",
    "DATA_PATH = \"./data\"\n",
    "OUT_PATH = \"./output\"\n",
    "DATA_UAV = \"UAV_Dataset\"\n",
    "DATA_GE = \"GoogleEarth_Dataset\"\n",
    "GE_DATA_PATH = f'{DATA_PATH}/{DATA_GE}'\n",
    "UAV_DATA_PATH = f'{DATA_PATH}/{DATA_UAV}'\n",
    "DATA_UAV_COMPRESSED_FILENAME = \"UAV_Dataset.zip\"\n",
    "DATA_BLOB_UAV_COMPRESSED = \"https://nlpdatastorage.blob.core.windows.net/cnndata/UAV_Dataset.zip\"\n",
    "DATA_GE_COMPRESSED_FILENAME = \"GoogleEarth_Dataset.zip\"\n",
    "DATA_BLOB_GE_COMPRESSED = \"https://nlpdatastorage.blob.core.windows.net/cnndata/GoogleEarth_Dataset.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(OUT_PATH, exist_ok=True)\n",
    "os.makedirs(DATA_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "import os, shutil\n",
    "do_cleanup = True\n",
    "def remove_folder(folder):\n",
    "    for filename in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print('Failed to delete %s. Reason: %s' % (file_path, e))\n",
    "if(do_cleanup):\n",
    "    remove_folder(f\"./{TENSORBOARD_PATH}\")\n",
    "    # remove_folder(DATA_PATH)\n",
    "    remove_folder(OUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## TENSORBOARD ########################\n",
    "writer = SummaryWriter(TENSORBOARD_PATH)\n",
    "###################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_uav_data =  DATA_UAV_COMPRESSED_FILENAME not in os.listdir(DATA_PATH) \n",
    "download_ge_data =  DATA_GE_COMPRESSED_FILENAME not in os.listdir(DATA_PATH) \n",
    "\n",
    "uav_zipped = f'{UAV_DATA_PATH}/{DATA_UAV_COMPRESSED_FILENAME}'\n",
    "ge_zipped = f'{GE_DATA_PATH}/{DATA_GE_COMPRESSED_FILENAME}'\n",
    "\n",
    "if(download_uav_data):\n",
    "    print(f\"Downloading data from {DATA_BLOB_UAV_COMPRESSED} and saving in {uav_zipped}\")\n",
    "    cnn_drone_net_utils.download_data(DATA_BLOB_UAV_COMPRESSED, out_path=uav_zipped)\n",
    "\n",
    "if(download_ge_data):\n",
    "    print(f\"Downloading data from {DATA_BLOB_GE_COMPRESSED} and saving in {ge_zipped}\")\n",
    "    cnn_drone_net_utils.download_data(DATA_BLOB_GE_COMPRESSED, out_path=ge_zipped)\n",
    "\n",
    "print(f\"Unzipping {uav_zipped} to directory {DATA_PATH}\")\n",
    "cnn_drone_net_utils.unzip_file(uav_zipped, DATA_PATH)\n",
    "\n",
    "print(f\"Unzipping {ge_zipped} to directory {DATA_PATH}\")\n",
    "cnn_drone_net_utils.unzip_file(ge_zipped, DATA_PATH)\n",
    "\n",
    "print(f\"{DATA_PATH} contents: {', '.join(os.listdir(DATA_PATH))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Hyper Parameters #####\n",
    "lr = 0.003\n",
    "batch_size = 8\n",
    "dropout = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = GE_DATA_PATH\n",
    "train_loader = cnn_drone_net_utils.load_dataset(train_data_dir, batch_size = batch_size)\n",
    "print(f'Initialized train set loader from directory {GE_DATA_PATH}, classes: {train_loader.dataset.classes}')\n",
    "\n",
    "val_data_dir = UAV_DATA_PATH\n",
    "val_loader = cnn_drone_net_utils.load_dataset(val_data_dir, batch_size = batch_size)\n",
    "print(f'Initialized validation set loader from directory {UAV_DATA_PATH}, classes: {val_loader.dataset.classes}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling train data set\n",
    "print(\"Sampling training set:\")\n",
    "examples = iter(train_loader)\n",
    "example_data, example_targets = examples.next()\n",
    "\n",
    "fig = figure(num=None, figsize=(10, 7.5))\n",
    "\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    plt.imshow(torchvision.utils.make_grid(example_data[i], nrow=1).permute(1, 2, 0))\n",
    "    plt.title(train_loader.dataset.classes[example_targets[i]])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "######################## TENSORBOARD ########################\n",
    "cnn_drone_net_utils.plot_to_tensorboard(\"training_set_sample\",writer, fig, 0)\n",
    "#############################################################\n",
    "\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling validation data set\n",
    "print(\"Sampling validation set:\")\n",
    "examples = iter(val_loader)\n",
    "example_data, example_targets = examples.next()\n",
    "\n",
    "fig = figure(num=None, figsize=(10, 7.5))\n",
    "\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    plt.imshow(torchvision.utils.make_grid(example_data[i], nrow=1).permute(1, 2, 0))\n",
    "    plt.title(train_loader.dataset.classes[example_targets[i]])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "######################## TENSORBOARD ########################\n",
    "cnn_drone_net_utils.plot_to_tensorboard(\"validation_set_sample\",writer, fig, 0)\n",
    "#############################################################\n",
    "\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = models.resnet50(pretrained=True)\n",
    "print(f'Loaded pretrained model: {models.resnet50.__name__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Freezing the pretrained model's parameters\")\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "print(\"Initialzing the last fully connected layer of the pretrained model\")\n",
    "model.fc = nn.Sequential(nn.Linear(2048, 512),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Dropout(dropout),\n",
    "                                 nn.Linear(512, 10),\n",
    "                                 nn.LogSoftmax(dim=1))\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=lr)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## TENSORBOARD ########################\n",
    "writer.add_graph(model, example_data.to(device))\n",
    "###################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2\n",
    "steps = 0\n",
    "running_loss = 0\n",
    "print_every = 1\n",
    "img_every = 3\n",
    "train_losses, val_losses = [], []\n",
    "for epoch in range(epochs):\n",
    "    for inputs, labels in train_loader:\n",
    "        steps += 1\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logps = model.forward(inputs)\n",
    "        loss = criterion(logps, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if steps % print_every == 0:\n",
    "            val_loss = 0\n",
    "            accuracy = 0\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for inputs, labels in val_loader:\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "                    logps = model.forward(inputs)\n",
    "                    batch_loss = criterion(logps, labels)\n",
    "                    val_loss += batch_loss.item()\n",
    "                    ps = torch.exp(logps)\n",
    "                    top_p, top_class = ps.topk(1, dim=1)\n",
    "                    equals = top_class == labels.view(*top_class.shape)\n",
    "                    \n",
    "                    ############## TENSORBOARD ########################\n",
    "                    right_predict_indices_sample = (equals).nonzero()[:1]\n",
    "                    wrong_predict_indices_sample = (equals == False).nonzero()[:1]\n",
    "\n",
    "                    if(len(right_predict_indices_sample)>0):\n",
    "                        if steps % img_every == 0:\n",
    "                            fig = figure(num=None, figsize=(7, 7))\n",
    "                            print(\"Good Predictions\")\n",
    "                            img_idx = right_predict_indices_sample[0][0]\n",
    "                            plt.imshow(torchvision.utils.make_grid(inputs[img_idx].cpu(), nrow=1).permute(1, 2, 0))\n",
    "                            plt.title(f'Predicted: {val_loader.dataset.classes[labels[img_idx]]}, P: {top_p[0].item()}')\n",
    "                            plt.show()\n",
    "                            cnn_drone_net_utils.plot_to_tensorboard(\"correct_predictions\",writer, fig, steps)\n",
    "                            plt.close()\n",
    "\n",
    "                    if(len(wrong_predict_indices_sample)>0):\n",
    "                        fig = figure(num=None, figsize=(7, 7))\n",
    "                        # print(\"Bad Predictions\")\n",
    "                        img_idx = wrong_predict_indices_sample[0][0]\n",
    "                        plt.imshow(torchvision.utils.make_grid(inputs[img_idx].cpu(), nrow=1).permute(1, 2, 0))\n",
    "                        plt.title(f'Expected: {val_loader.dataset.classes[labels[img_idx]]}')\n",
    "                        # plt.show()\n",
    "                        cnn_drone_net_utils.plot_to_tensorboard(\"wrong_predictions\",writer, fig, steps)\n",
    "                        plt.close()\n",
    "                    ###################################################\n",
    "\n",
    "                    accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "                    \n",
    "            train_losses.append(running_loss / len(train_loader))\n",
    "            val_losses.append(val_loss / len(val_loader))\n",
    "            print(f\"Epoch {epoch + 1}/{epochs}.. \"\n",
    "                  f\"Train loss: {running_loss / print_every:.3f}.. \"\n",
    "                  f\"Validation loss: {val_loss / len(val_loader):.3f}.. \"\n",
    "                  f\"Validation accuracy: {accuracy / len(val_loader):.3f} \"\n",
    "                  f\"Step: {steps}/{len(train_loader)*epochs}\")\n",
    "            ############## TENSORBOARD ########################\n",
    "            writer.add_scalar('training loss', running_loss / print_every, steps)\n",
    "            writer.add_scalar('validation accuracy', accuracy / len(val_loader), steps)\n",
    "            writer.add_scalar('validation loss', val_loss / len(val_loader), steps)\n",
    "            running_correct = 0\n",
    "            running_loss = 0.0\n",
    "            ###################################################\n",
    "            running_loss = 0\n",
    "            model.train()\n",
    "            \n",
    "print(\"Done training model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, f'{OUT_PATH}/model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(val_losses, label='Validation loss')\n",
    "plt.legend(frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## TENSORBOARD ########################\n",
    "writer.close()\n",
    "###################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
